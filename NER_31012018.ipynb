{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Name: entity identification\n",
    "# Target: entity identification of text, including non-regular cases\n",
    "#         each entity is tagged in one of the following tags:\n",
    "#         {PERSON}- A first or last name (sometimes also an affix)\n",
    "#         {GPE}- A geographical political entity\n",
    "#         {CARDINAL} - Quantity/Number\n",
    "#         {ORG} -Organization\n",
    "#         {LOCATION} - location\n",
    "#         {DATE} - Date\n",
    "#         {UNIDENTIFIED_NAME} - A name- Usually last name taht wasn't identified by the list\n",
    "#         {TIME} - Time\n",
    "#         {PHONE} - Phone number\n",
    "#         {MAIL} - E-mail\n",
    "#         {FAC} - Facility\n",
    "#         {MONNEY} - Money\n",
    "# Recieves : a Plain text, a name list \n",
    "# Return : A tagged text\n",
    "# Author: Yonathan Guttel\n",
    "# Last Edited: 31.01.2018\n",
    "# Version: 3\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Package imports\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set path\n",
    "path='F:\\Guttel\\Desktop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here is where to put the text or upload it\n",
    "\n",
    "my_text =\"\"\"yesterday I've met Dave and Carly, we want to the cinema at 5 o'clock to watch the new movie of Mel Gibson, I didn't like it, but we thought that the main actor Tim, was preforming great. An hour later we went to drink coffee at Starbucks which was super expensive 10$ for a normal cappuccino! I also paid five dollars for a cookie. I think that such think could never happen in Jerusalem or in Switzerland.  Dave ask me to give you his details:  Dave Matthews, 02-5702338, at work it is zero five two five five ten eight seven. His mail address is dave@gmail.com and at the university is: dmat at Stanford dot ac dot cam. He will stay in the US for four months in 2018 and then will get back to England where his wife Katy, leaves. They have a beautiful house in London which cost them 1 and a half million pounds. Send my regard to Monika and tell her to salute Mike Gonzales in my behalf. Lots of love Debbi. P.s. call my back on 3.12.18 on the mail dcohen@hotmail.au or in my work: ddebbie at embassyus dot com or on my phone 0549994893\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phone_tagger (text):\n",
    "    digits_list=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\",\"-\",\",\",\"_\",\"zero\",\n",
    "                 \"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\",\"nine\",\"o\"]\n",
    "    split_text = text.split()\n",
    "    new_text=[]\n",
    "    count = 0\n",
    "    for i in split_text:\n",
    "        if i.lower() in digits_list:\n",
    "            new_text.append(i)\n",
    "            count+=1\n",
    "        elif bool(re.match(r\"([\\W*\\d*])\", i)) and len(i)>5:\n",
    "            new_text.append(i)\n",
    "            new_text.append(\"{PHONE}\")\n",
    "            count=0\n",
    "        else:\n",
    "            if count>5:\n",
    "                new_text.append(i)\n",
    "                new_text.append(\"{PHONE}\")\n",
    "                count=0\n",
    "            else:\n",
    "                new_text.append(i)\n",
    "                count=0\n",
    "    returned_text= \"\".join([\" \" + i if not i.startswith(\"'\") and i not in string.punctuation else i for i in new_text]).strip()\n",
    "    return(returned_text)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mail_tagger(text):\n",
    "    #email_words =[\"at\",\"@\",\"dot\",\"com\",\".com\",\"gmail\",\"hotmail\", \"email\", \"e-mail\", \"mail\",\"electronic mail\"]\n",
    "    text_split=text.split()\n",
    "    new_text=[]\n",
    "\n",
    "    # identify format \"bla at bla dot bla\"\n",
    "    if bool(re.findall(r\"(\\S*\\s?at\\s*\\S*\\s*dot\\s\\S*)\",text)):\n",
    "        sub_mail=  re.findall(r\"(\\S*\\s?at\\s*\\S*\\s*dot\\s\\S*)\", text)\n",
    "        ind1=0\n",
    "        for sub in sub_mail:\n",
    "            for w in sub.split():\n",
    "                ind1=text_split.index(w, ind1)\n",
    "                text_split.insert(ind1+1, \"{MAIL}\")\n",
    "                \n",
    "    # identify format \"bla at bla dot bla dot bla\"\n",
    "    if bool(re.findall(r\"(\\S*\\s?at\\s*\\S*\\s*dot\\s*\\S*\\s?dot?\\s?\\S*)\",text)):\n",
    "        sub_mail=  re.findall(r\"(\\S*\\s?at\\s*\\S*\\s*dot\\s*\\S*\\s?dot?\\s?\\S*)\", text)\n",
    "        ind1=0\n",
    "        for sub in sub_mail:\n",
    "            for w in sub.split():\n",
    "                ind1=text_split.index(w, ind1)\n",
    "                text_split.insert(ind1+1, \"{MAIL}\")\n",
    "            \"\"\"yesterday I've met Dave and Carly, we want to the cinema at 5 o'clock to watch the new movie of Mel Gibson, I didn't like it, but we thought that the main actor Tim, was preforming great. An hour later we went to drink coffee at Starbucks which was super expensive 10$ for a normal cappuccino! I also paid five dollars for a cookie, and thing that was never could happened in Orlando or in Switzerland.  Dave ask me to give you his details:  Dave Matthews, 02-5702338, at work it is zero five two five five ten eight seven. His mail address is dave@gmail.com and at the university is: dmat at Stanford dot ac dot cam. He will stay in the US for four months in 2018 and then will get back to England where his wife Katy, leaves. They have a beautiful house in London which cost them 1 and a half million pounds. Send my regard to Monika and tell her to salute Mike Gonzales in my behalf. Lots of love Debbi\"\"\"       \n",
    "    # identify format \"XXXXXXXX@XXXXXX.XXX\"\n",
    "    for i in text_split:\n",
    "        if bool(re.match(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\", i)):\n",
    "            new_text.append(i)\n",
    "            new_text.append(\"{MAIL}\")\n",
    "        else:\n",
    "            new_text.append(i)\n",
    "     \n",
    "    returned_text= \"\".join([\" \" + i if not i.startswith(\"'\") and i not in string.punctuation else i for i in new_text]).strip()\n",
    "    return(returned_text)            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name entity tagger using SpaCy package\n",
    "def spacy_entity_extractor(text):\n",
    "    nlp=spacy.load('en')\n",
    "    doc = nlp(text)\n",
    "    new_doc=text\n",
    "    add=0\n",
    "    # Iterate over the text list and add entity when there is\n",
    "    for ent in doc.ents:\n",
    "            new_doc= new_doc[:ent.end_char+add] + ' {'+str(ent.label_) + '} ' + new_doc[ent.end_char+add:]\n",
    "            add=add+(len(ent.label_))+4\n",
    "    return(new_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name entity tagger using nltk package\n",
    "def nltk_entity_extractor(text):\n",
    "    \n",
    "    #find part of speach and entities in text\n",
    "    namedEnt = nltk.ne_chunk(nltk.pos_tag(text.split()))\n",
    "\n",
    "    #create a dictionary to set the names of the tags\n",
    "    replacement_dic={'PERSON':\"{PERSON}\",'GPE':'{GPE}','ORGANIZATION':'{ORG}','FACILITY':{'FAC'}}\n",
    "\n",
    "    # create a list to store the edited text\n",
    "    edited_data_list=[]\n",
    "    #iterate over the the text and tag it accordingly\n",
    "    for i in range(len(namedEnt)):\n",
    "        if type(namedEnt[i][0])==type('str'):\n",
    "            edited_data_list.append(namedEnt[i][0])\n",
    "            if namedEnt[i][1]=='NNP':\n",
    "                edited_data_list.append('{UNIDENTIFIED_NAME}')\n",
    "        else:\n",
    "            for j in range(len(namedEnt[i])):\n",
    "                edited_data_list.append(namedEnt[i][j][0])\n",
    "                edited_data_list.append(replacement_dic[namedEnt[i].label()])\n",
    "\n",
    "    # Join the list back to text\n",
    "    edited_data = \"\".join([\" \" + str(i) if not str(i).startswith(\"'\") and str(i) not in string.punctuation else str(i) for i in edited_data_list]).strip()\n",
    "    return (edited_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name entity tagger using an external name list\n",
    "def list_entity_extractor(text):\n",
    "    split_text=text.split()\n",
    "    new_text=[]\n",
    "    #upload list and extract the name column\n",
    "    names_df = pd.read_csv(\"names_list.csv\")\n",
    "    names_list=names_df[\"Name\"]\n",
    "    \n",
    "    #iterate over the the text and tag it accordingly\n",
    "    for i in split_text:\n",
    "        new_text.append(i)\n",
    "        name= \"\".join(re.findall(r'[a-zA-z]', i))\n",
    "        if name in list(names_list):\n",
    "            new_text.append('{PERSON}')\n",
    "    returned_text= \"\".join([\" \" + i if not i.startswith(\"'\") and i not in string.punctuation else i for i in new_text]).strip()\n",
    "    return(returned_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to remove double tagging (in cast multiple NET are used)\n",
    "def remove_repeated_ent(text):\n",
    "    split_text=text.split()\n",
    "    dec=0\n",
    "    for i in range(len(split_text)-1):\n",
    "        if split_text[i-dec].startswith(\"{\") and split_text[i+1-dec].startswith(\"{\"):\n",
    "            del split_text[i+1-dec]\n",
    "            dec +=1\n",
    "        elif split_text[i-dec]=='),' and split_text[i+1-dec].startswith(\"{\"):\n",
    "            del split_text[i+1-dec]\n",
    "            dec +=1\n",
    "    returned_text= \"\".join([\" \" + i if not i.startswith(\"'\") and i not in string.punctuation else i for i in split_text]).strip()\n",
    "    return(returned_text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compinning all above functions\n",
    "def multi_NER_tagger(text):\n",
    "    text_1 = spacy_entity_extractor(text)\n",
    "    text_2 = nltk_entity_extractor(text_1)\n",
    "    text_3 = list_entity_extractor(text_2)\n",
    "    text_4 = phone_tagger(text_3)\n",
    "    text_5 = mail_tagger(text_4)\n",
    "    text_6 = remove_repeated_ent(text_5)\n",
    "    return(text_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yesterday {DATE} I've {PERSON} met Dave {PERSON} and Carly, {PERSON} we want to the cinema at 5 o'clock {TIME} to watch the new movie of Mel {PERSON} Gibson {PERSON} I didn't like it, but we thought that the main actor Tim {PERSON} was preforming great. An {PERSON} hour later {TIME} we went to drink coffee at Starbucks {'FAC'} which was super expensive 10$ {MONEY} for a normal cappuccino! I also paid five dollars {MONEY} for a cookie. I think that such think could never happen in Jerusalem {PERSON} or in Switzerland {GPE} Dave {PERSON} ask me to give you his details: {NORP} Dave {PERSON} Matthews {PERSON} 02-5702338 {PHONE} at work it is zero {CARDINAL} five {CARDINAL} two {CARDINAL} five {CARDINAL} five {CARDINAL} ten {CARDINAL} eight {CARDINAL} seven {CARDINAL} His mail address is dave@gmail.com {MAIL} and at the university is: dmat at Stanford {PERSON} dot ac dot cam. He will stay in the US {ORG} for four months {DATE} in 2018 {DATE} and then will get back to England {PERSON} where his wife Katy {PERSON} leaves. They have a beautiful house in London {PERSON} which cost them 1 {CARDINAL} and a half million pounds. Send {UNIDENTIFIED_NAME} my regard to Monika {PERSON} and tell her to salute Mike {PERSON} Gonzales {PERSON} in my behalf. Lots {UNIDENTIFIED_NAME} of love Debbi {PERSON} P.s. {UNIDENTIFIED_NAME} call my back on 3.12.18 {PHONE} on the mail dcohen@hotmail.au {MAIL} or in my work: ddebbie {MAIL} at {MAIL} embassyus {MAIL} dot {MAIL} com {MAIL} or on my phone 0549994893 {PHONE}\n"
     ]
    }
   ],
   "source": [
    "print(multi_NER_tagger(my_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = spacy_entity_extractor(my_text)\n",
    "text_2 = nltk_entity_extractor(text_1)\n",
    "text_3 = list_entity_extractor(text_2)\n",
    "text_4 = phone_tagger(text_3)\n",
    "text_5 = mail_tagger(text_4)\n",
    "text_6 = remove_repeated_ent(text_5) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
